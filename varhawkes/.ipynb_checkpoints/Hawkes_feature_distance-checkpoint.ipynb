{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#距离\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "#缩放马氏距离\n",
    "def trainScaledManhattan(in_vec):\n",
    "    mean = in_vec.mean()\n",
    "    std = in_vec.std()\n",
    "    return mean,std\n",
    "\n",
    "\n",
    "def classifyScaledManhattan(mean,std, q, prob_list):\n",
    "\n",
    "    if(len(mean) != len(q)):\n",
    "        print (len(mean))\n",
    "        print(len(q))\n",
    "        print(\"Be sure that both vectors are the same dimension!\")\n",
    "        return\n",
    "    for i in range(len(mean)):\n",
    "        if (std[i] == 0):\n",
    "            std[i] = 1e-10\n",
    "\n",
    "    return sum([prob_list[i] * abs(mean[i]-q[i])/std[i] for i in range(len(q))])\n",
    "\n",
    "#欧氏距离\n",
    "def trainEuclidean(in_vec):\n",
    "    mean = in_vec.mean()\n",
    "    return mean\n",
    "\n",
    "def classifyEuclidean(mean,q, prob_list):\n",
    "    if(len(mean) != len(q)):\n",
    "        print (len(mean))\n",
    "        print(len(q))\n",
    "        print(\"Be sure that both vectors are the same dimension!\")\n",
    "        return\n",
    "    return sum([prob_list[i]*math.sqrt((mean[i]-q[i])**2) for i in range(len(q))])\n",
    "\n",
    "#根据距离搜索阀值\n",
    "def search_threshold(scores,threshold):\n",
    "    scores_asc = sorted(scores)\n",
    "    #print(scores_asc)\n",
    "    threshold_index = int(len(scores)*(1-threshold))\n",
    "    return scores_asc[threshold_index]\n",
    "\n",
    "\n",
    "#调整的余弦相似度量\n",
    "\n",
    "from scipy import spatial\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def adjusted_cos_distance_matrix(size, matrix, row_column, prob_list):\n",
    "    distances = np.zeros((size,size))\n",
    "    if row_column == 0:\n",
    "        M_u = matrix.mean(axis=1)\n",
    "        #print('M_u is:',M_u)\n",
    "        m_sub = matrix.as_matrix() - M_u[:,None]\n",
    "        #print('m_sub is:',m_sub)\n",
    "    if row_column == 1:\n",
    "        M_u = matrix.df.as_matrix().T.mean(axis=1)\n",
    "        m_sub = matrix.T - M_u[:,None]\n",
    "    \n",
    "    prob_Matrix = []\n",
    "    for i in range(len(m_sub)):\n",
    "        prob_Matrix.append(prob_list)\n",
    "    print('m_sub is:',m_sub)\n",
    "    \n",
    "    m_sub = m_sub*np.array(prob_Matrix)\n",
    "    print('secend m_sub is:',m_sub)\n",
    "    \n",
    "    for first in range(0,size):\n",
    "        for sec in range(0,size):\n",
    "            distance = spatial.distance.cosine(m_sub[first],m_sub[sec])\n",
    "            distances[first,sec] = distance\n",
    "            if distance < 0:\n",
    "                print('distance matrix',distance)\n",
    "    return distances\n",
    "\n",
    "\n",
    "def adjusted_cos_distance(vector1,vector2,prob_list):\n",
    "    M_u1 = vector1.mean()\n",
    "    M_u2 = vector2.mean()\n",
    "    m_sub1 = vector1 - M_u1\n",
    "    m_sub2 = vector2 - M_u2    \n",
    "    m_sub1 = np.multiply(np.array(m_sub1),np.array(prob_list))\n",
    "    print(m_sub1)\n",
    "    m_sub2 = np.multiply(np.array(m_sub2),np.array(prob_list))\n",
    "    print(m_sub2)\n",
    "    distance = spatial.distance.cosine(m_sub1,m_sub2)\n",
    "    if distance < 0:\n",
    "        print(distance)\n",
    "    return distance\n",
    "\n",
    "def cos_distance_matrix(size, matrix, row_column,prob_list):\n",
    "    distances = np.zeros((size,size))\n",
    "    if row_column == 0:\n",
    "        m_sub = matrix.as_matrix() \n",
    "        #print('m_sub is:',m_sub)\n",
    "    if row_column == 1:\n",
    "        M_u = matrix.df.as_matrix().T.mean(axis=1)\n",
    "        m_sub = matrix.T\n",
    "    \n",
    "    prob_Matrix = []\n",
    "    for i in range(len(m_sub)):\n",
    "        prob_Matrix.append(prob_list)\n",
    "    \n",
    "    m_sub = m_sub*np.array(prob_Matrix)\n",
    "    \n",
    "    \n",
    "    for first in range(0,size):\n",
    "        for sec in range(0,size):\n",
    "            distance = spatial.distance.cosine(m_sub[first],m_sub[sec])\n",
    "            distances[first,sec] = distance\n",
    "    return distances\n",
    "\n",
    "def cos_distance(vector1,vector2,prob_list):\n",
    "    m_sub1 = vector1\n",
    "    m_sub2 = vector2\n",
    "    m_sub1 = np.multiply(np.array(m_sub1),np.array(prob_list))\n",
    "    m_sub2 = np.multiply(np.array(m_sub2),np.array(prob_list))    \n",
    "    distance = spatial.distance.cosine(m_sub1,m_sub2)\n",
    "    if distance < 0:\n",
    "        print(distance)\n",
    "    return distance\n",
    "\n",
    "\n",
    "#中心点对应的index,0.05false alarm的distance阀值\n",
    "def center (subject,vectors,prob_list):    #根据前200个样本计算中心点\n",
    "    subject_vecs = vectors[vectors['subject']==subject].drop(['subject'],axis=1)[0:200]\n",
    "    distances = adjusted_cos_distance_matrix(200,subject_vecs,0,prob_list)\n",
    "    #print(distances)\n",
    "    distances_sum = pd.DataFrame(distances).sum().tolist()\n",
    "    #print(distances_sum)\n",
    "    center_index  = distances_sum.index(min(distances_sum))\n",
    "    return subject_vecs.iloc[center_index]\n",
    "\n",
    "def cosine_threshold (center_vec,vectors,prob_list):\n",
    "    subject_vecs = vectors[vectors['subject']==subject].drop(['subject'],axis=1)[0:200]\n",
    "    possitive_scores = []\n",
    "    for i in range(len(subject_vecs)):\n",
    "        distance = adjusted_cos_distance(center_vec,subject_vecs.iloc[i],prob_list)\n",
    "        possitive_scores.append(distance)\n",
    "    #print(sorted(possitive_scores))\n",
    "    threshold = search_threshold(possitive_scores,0.05)\n",
    "    return threshold\n",
    "    \n",
    "\n",
    "def test_possitive(subject,vectors,center_vec,distance_threshold,prob_list): \n",
    "    positive_vecs = vectors[vectors['subject']==subject].drop(['subject'],axis=1)[200:400]\n",
    "    possitive_scores = []\n",
    "    for i in range(len(positive_vecs)):\n",
    "        distance = adjusted_cos_distance(center_vec,positive_vecs.iloc[i],prob_list)\n",
    "        possitive_scores.append(distance)\n",
    "    #print(possitive_scores)\n",
    "    negative1 = sum(possitive_scores>distance_threshold)\n",
    "    #print(negative1)\n",
    "    return negative1\n",
    "\n",
    "def test_passitive(subject,vectors,center_vec,distance_threshold,prob_list):\n",
    "    negative_vecs = vectors[vectors['subject']!=subject].drop(['subject'],axis=1)    \n",
    "    negative_scores = []\n",
    "    for i in range(len(negative_vecs)):\n",
    "        distance = adjusted_cos_distance(center_vec,negative_vecs.iloc[i],prob_list)\n",
    "        negative_scores.append(distance)\n",
    "    #print(sorted(negative_scores))\n",
    "    negative2 = sum(negative_scores<distance_threshold)\n",
    "    #print(negative2)\n",
    "    return negative2\n",
    "\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#ss = StandardScaler()\n",
    "\n",
    "def train (subject,vectors,prob_list):\n",
    "    subject_vecs = vectors[vectors['subject']==subject].drop(['subject'],axis=1)[0:200]  #前200个样本训练，后200个样本测试\n",
    "    mean,std = trainScaledManhattan(subject_vecs)\n",
    "    \n",
    "    scores = []   \n",
    "    for i in range(len(subject_vecs)):\n",
    "        score = classifyScaledManhattan(mean,std,subject_vecs.iloc[i],prob_list)\n",
    "        #print(possitive_score)\n",
    "        scores.append(score)\n",
    "        \n",
    "    threshold = search_threshold(scores,0.05)\n",
    "    #subject_vecs = ss.fit_transform(subject_vecs)    \n",
    "    \n",
    "    return mean,std,threshold\n",
    "\n",
    "def test(subject,vectors,prob_list):\n",
    "    mean,std,threshold = train(subject,vectors,prob_list)    #调用训练\n",
    "    #print('mean:',mean)\n",
    "    #print('std:',std)\n",
    "    possitive_samples = vectors[vectors['subject']==subject].drop(['subject'],axis=1)[200:400]  #正样本\n",
    "    #possitive_samples = ss.fit_transform(possitive_samples)\n",
    "    negative_samples = vectors[vectors['subject']!=subject].drop(['subject'],axis=1)\n",
    "    #negative_samples = ss.fit_transform(negative_samples)\n",
    "    \n",
    "    #print(possitive_samples)\n",
    "    #print(negative_samples)\n",
    "    \n",
    "    possitive_scores = []\n",
    "    negative_scores = []\n",
    "    \n",
    "    for i in range(len(possitive_samples)):\n",
    "        possitive_score = classifyScaledManhattan(mean,std,possitive_samples.iloc[i],prob_list)\n",
    "        #print(possitive_score)\n",
    "        possitive_scores.append(possitive_score)\n",
    "        \n",
    "    for i in range(len(negative_samples)):\n",
    "        negative_score = classifyScaledManhattan(mean,std,negative_samples.iloc[i],prob_list)\n",
    "        #print(negative_score)\n",
    "        negative_scores.append(negative_score)\n",
    "    return possitive_scores,negative_scores,threshold\n",
    "\n",
    "#纯余弦度量\n",
    "#中心点对应的index,0.05false alarm的distance阀值\n",
    "def center2 (subject,vectors,prob_list):    #根据前200个样本计算中心点\n",
    "    subject_vecs = vectors[vectors['subject']==subject].drop(['subject'],axis=1)[0:200]\n",
    "    distances = cos_distance_matrix(200,subject_vecs,0,prob_list)\n",
    "    #print(distances)\n",
    "    distances_sum = pd.DataFrame(distances).sum().tolist()\n",
    "    #print(distances_sum)\n",
    "    center_index  = distances_sum.index(min(distances_sum))\n",
    "    return subject_vecs.iloc[center_index]\n",
    "\n",
    "def cosine_threshold2 (center_vec,vectors,prob_list):\n",
    "    subject_vecs = vectors[vectors['subject']==subject].drop(['subject'],axis=1)[0:200]\n",
    "    possitive_scores = []\n",
    "    for i in range(len(subject_vecs)):\n",
    "        distance = cos_distance(center_vec,subject_vecs.iloc[i],prob_list)\n",
    "        possitive_scores.append(distance)\n",
    "        if distance < 0:\n",
    "            print('distance threshold2:',distance)\n",
    "    #print(sorted(possitive_scores))\n",
    "    threshold = search_threshold(possitive_scores,0.05)\n",
    "    return threshold\n",
    "    \n",
    "\n",
    "def test_possitive2(subject,vectors,center_vec,distance_threshold,prob_list): \n",
    "    positive_vecs = vectors[vectors['subject']==subject].drop(['subject'],axis=1)[200:400]\n",
    "    possitive_scores = []\n",
    "    for i in range(len(positive_vecs)):\n",
    "        distance = cos_distance(center_vec,positive_vecs.iloc[i],prob_list)\n",
    "        possitive_scores.append(distance)\n",
    "        if distance < 0:\n",
    "            print(distance)\n",
    "    #print(possitive_scores)\n",
    "    negative1 = sum(possitive_scores>distance_threshold)\n",
    "    #print(negative1)\n",
    "    return negative1\n",
    "\n",
    "def test_passitive2(subject,vectors,center_vec,distance_threshold,prob_list):\n",
    "    negative_vecs = vectors[vectors['subject']!=subject].drop(['subject'],axis=1)    \n",
    "    negative_scores = []\n",
    "    for i in range(len(negative_vecs)):\n",
    "        distance = cos_distance(center_vec,negative_vecs.iloc[i],prob_list)\n",
    "        negative_scores.append(distance)\n",
    "        if distance < 0:\n",
    "            print(distance)\n",
    "    #print(sorted(negative_scores))\n",
    "    negative2 = sum(negative_scores<distance_threshold)\n",
    "    #print(negative2)\n",
    "    return negative2\n",
    "\n",
    "#试试欧氏距离\n",
    "\n",
    "def train_Euclidean (subject,vectors,prob_list):\n",
    "    subject_vecs = vectors[vectors['subject']==subject].drop(['subject'],axis=1)[0:200]  #前200个样本训练，后200个样本测试\n",
    "    mean = trainEuclidean(subject_vecs)\n",
    "    \n",
    "    scores = []   \n",
    "    for i in range(len(subject_vecs)):\n",
    "        score = classifyEuclidean(mean,subject_vecs.iloc[i],prob_list)\n",
    "        #print(score)\n",
    "        scores.append(score)\n",
    "        \n",
    "    threshold = search_threshold(scores,0.05)\n",
    "    #subject_vecs = ss.fit_transform(subject_vecs)    \n",
    "    \n",
    "    return mean,threshold\n",
    "\n",
    "def test_Euclidean(subject,vectors,prob_list):\n",
    "    mean,threshold = train_Euclidean(subject,vectors,prob_list)    #调用训练\n",
    "    #print('mean:',mean)\n",
    "    #print('std:',std)\n",
    "    possitive_samples = vectors[vectors['subject']==subject].drop(['subject'],axis=1)[200:400]  #正样本\n",
    "    #possitive_samples = ss.fit_transform(possitive_samples)\n",
    "    negative_samples = vectors[vectors['subject']!=subject].drop(['subject'],axis=1)\n",
    "    #negative_samples = ss.fit_transform(negative_samples)\n",
    "    \n",
    "    #print(possitive_samples)\n",
    "    #print(negative_samples)\n",
    "    \n",
    "    possitive_scores = []\n",
    "    negative_scores = []\n",
    "    \n",
    "    for i in range(len(possitive_samples)):\n",
    "        possitive_score = classifyEuclidean(mean,possitive_samples.iloc[i],prob_list)\n",
    "        #print(possitive_score)\n",
    "        possitive_scores.append(possitive_score)\n",
    "        \n",
    "    for i in range(len(negative_samples)):\n",
    "        negative_score = classifyEuclidean(mean,negative_samples.iloc[i],prob_list)\n",
    "        #print(negative_score)\n",
    "        negative_scores.append(negative_score)\n",
    "    return possitive_scores,negative_scores,threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hawkes模型提出的特征，表明激励有没有有，有的话，强度是多少。考虑有没有，我用训练集中的特征出现的概率p（发生率）的导数作为惩罚，即，如果训练集中这个特征基本没有值，如果测试集中，该特征有值，那么判断很可以能不是该用户，所以这种情况，需要对该特征产生的距离进行惩罚。惩罚系数为beta/p。beta控制惩罚的力度。\n",
    "下面在计算距离时，每个特征的距离要乘以这个惩罚系数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#求训练集中的各特征出现的概率\n",
    "# inf_pen 是特征不出现，zero_counts = 0的情况，在 zero_counts = 1的基础上再加一个惩罚inf_pen, beta是惩罚项的影响比率\n",
    "def prob(subject, vectors, samples_start, samples_end, beta, inf_pen = 10):\n",
    "    subject_vecs = vectors[vectors['subject']==subject].drop(['subject'],axis=1)[samples_start:samples_end]\n",
    "    prob_list = []\n",
    "    for columns in [column for column in subject_vecs]:\n",
    "        zero_counts = len(subject_vecs[subject_vecs[columns]==0])\n",
    "        if zero_counts == 0:\n",
    "            prob = samples_end - samples_start + inf_pen\n",
    "        else:\n",
    "            prob = (samples_end - samples_start)/zero_counts\n",
    "        prob_list.append(prob**beta)\n",
    "    return prob_list     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s002 miss_rate1 is: 0.105\n",
      "s002 miss_rate2 is: 0.52125\n",
      "s002 miss_rate is: 0.475\n",
      "s032 miss_rate1 is: 0.05\n",
      "s032 miss_rate2 is: 0.5375\n",
      "s032 miss_rate is: 0.48333333333333334\n",
      "s036 miss_rate1 is: 0.175\n",
      "s036 miss_rate2 is: 0.000625\n",
      "s036 miss_rate is: 0.02\n",
      "s047 miss_rate1 is: 0.145\n",
      "s047 miss_rate2 is: 0.33125\n",
      "s047 miss_rate is: 0.31055555555555553\n",
      "s052 miss_rate1 is: 0.105\n",
      "s052 miss_rate2 is: 0.350625\n",
      "s052 miss_rate is: 0.3233333333333333\n"
     ]
    }
   ],
   "source": [
    "file_name = './data/CMU_exp_shrink_output_zero_2subject.xls'\n",
    "#file_name = './data/CMU_exp_shrink_output_rep50_2subject.xls'\n",
    "df = pd.read_excel(file_name)\n",
    "vectors = df.drop(['key','session'],axis=1)\n",
    "samples_start = 0\n",
    "samples_end = 200\n",
    "beta = 1\n",
    "inf_pen = 1\n",
    "\n",
    "subject_list = ['s002','s032','s036','s047','s052']\n",
    "for subject in subject_list:\n",
    "    prob_list  = prob(subject,vectors,samples_start,samples_end,beta,inf_pen)\n",
    "    #print (prob_list)\n",
    "    positive_scores,negative_scores,threshold = test_Euclidean(subject,vectors,prob_list)\n",
    "    negative1 = sum(i > threshold for i in positive_scores)\n",
    "    negative2 = sum(i < threshold for i in negative_scores)\n",
    "    \n",
    "    miss_rate1 = negative1/200\n",
    "    miss_rate2 = negative2/1600\n",
    "    miss_rate = (negative1+negative2)/1800\n",
    "    \n",
    "    \n",
    "    print (subject+' miss_rate1 is:',miss_rate1)\n",
    "    print (subject+' miss_rate2 is:',miss_rate2)\n",
    "    print (subject+' miss_rate is:',miss_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s002 miss_rate1 is: 0.1\n",
    "s002 miss_rate2 is: 0.525\n",
    "s002 miss_rate is: 0.4777777777777778\n",
    "s032 miss_rate1 is: 0.05\n",
    "s032 miss_rate2 is: 0.535625\n",
    "s032 miss_rate is: 0.4816666666666667\n",
    "s036 miss_rate1 is: 0.175\n",
    "s036 miss_rate2 is: 0.000625\n",
    "s036 miss_rate is: 0.02\n",
    "s047 miss_rate1 is: 0.135\n",
    "s047 miss_rate2 is: 0.339375\n",
    "s047 miss_rate is: 0.31666666666666665\n",
    "s052 miss_rate1 is: 0.105\n",
    "s052 miss_rate2 is: 0.34125\n",
    "s052 miss_rate is: 0.315"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jw\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:93: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s002 miss_rate1 is: 0.085\n",
      "s002 miss_rate2 is: 0.4375\n",
      "s002 miss_rate is: 0.3983333333333333\n",
      "s032 miss_rate1 is: 0.12\n",
      "s032 miss_rate2 is: 0.725625\n",
      "s032 miss_rate is: 0.6583333333333333\n",
      "s036 miss_rate1 is: 0.355\n",
      "s036 miss_rate2 is: 0.00375\n",
      "s036 miss_rate is: 0.042777777777777776\n",
      "s047 miss_rate1 is: 0.035\n",
      "s047 miss_rate2 is: 0.595\n",
      "s047 miss_rate is: 0.5327777777777778\n",
      "s052 miss_rate1 is: 0.035\n",
      "s052 miss_rate2 is: 0.2175\n",
      "s052 miss_rate is: 0.19722222222222222\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_name = './data/CMU_exp_shrink_output_zero_2subject.xls'\n",
    "df = pd.read_excel(file_name)\n",
    "vectors = df.drop(['key','session'],axis=1)\n",
    "\n",
    "samples_start = 0\n",
    "samples_end = 200\n",
    "beta = 1\n",
    "inf_pen = 1\n",
    "\n",
    "subject_list = ['s002','s032','s036','s047','s052']\n",
    "#subject_list = ['s002']\n",
    "for subject in subject_list:\n",
    "    prob_list  = prob(subject,vectors,samples_start,samples_end,beta,inf_pen)\n",
    "    center_vec = center2(subject,vectors,prob_list)    \n",
    "    distance_threshold =  cosine_threshold2(center_vec,vectors,prob_list)\n",
    "    #print(distance_threshold)\n",
    "    negative1 = test_possitive2(subject,vectors,center_vec,distance_threshold,prob_list)\n",
    "    negative2 = test_passitive2(subject,vectors,center_vec,distance_threshold,prob_list)\n",
    "\n",
    "    miss_rate1 = negative1/200\n",
    "    miss_rate2 = negative2/1600\n",
    "    miss_rate = (negative1+negative2)/1800\n",
    "    \n",
    "    print (subject+' miss_rate1 is:',miss_rate1)\n",
    "    print (subject+' miss_rate2 is:',miss_rate2)\n",
    "    print (subject+' miss_rate is:',miss_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "OverflowError",
     "evalue": "(34, 'Result too large')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-b1647d7be6fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#subject_list = ['s002']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msubject\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msubject_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mprob_list\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mprob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubject\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvectors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msamples_start\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msamples_end\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minf_pen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mcenter_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcenter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubject\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvectors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprob_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mdistance_threshold\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mcosine_threshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcenter_vec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvectors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprob_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-336723c376ff>\u001b[0m in \u001b[0;36mprob\u001b[1;34m(subject, vectors, samples_start, samples_end, beta, inf_pen)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msamples_end\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0msamples_start\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mzero_counts\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mprob_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mprob_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOverflowError\u001b[0m: (34, 'Result too large')"
     ]
    }
   ],
   "source": [
    "file_name = './data/CMU_exp_shrink_output_zero_2subject.xls'\n",
    "#file_name = './data/CMU_exp_shrink_output_rep50_2subject.xls'\n",
    "df = pd.read_excel(file_name)\n",
    "vectors = df.drop(['key','session'],axis=1)\n",
    "\n",
    "samples_start = 0\n",
    "samples_end = 200\n",
    "beta = 1\n",
    "inf_pen = 200\n",
    "\n",
    "\n",
    "subject_list = ['s002','s032','s036','s047','s052']\n",
    "#subject_list = ['s002']\n",
    "for subject in subject_list:\n",
    "    prob_list  = prob(subject,vectors,samples_start,samples_end,beta,inf_pen)\n",
    "    center_vec = center(subject,vectors,prob_list)\n",
    "    distance_threshold =  cosine_threshold(center_vec,vectors,prob_list)\n",
    "    print(distance_threshold)\n",
    "    negative1 = test_possitive(subject,vectors,center_vec,distance_threshold,prob_list)\n",
    "    negative2 = test_passitive(subject,vectors,center_vec,distance_threshold,prob_list)\n",
    "\n",
    "    miss_rate1 = negative1/200\n",
    "    miss_rate2 = negative2/1600\n",
    "    miss_rate = (negative1+negative2)/1800\n",
    "    \n",
    "    print (subject+' miss_rate1 is:',miss_rate1)\n",
    "    print (subject+' miss_rate2 is:',miss_rate2)\n",
    "    print (subject+' miss_rate is:',miss_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-121.96928946530988"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = spatial.distance.cosine([1,10000000,1,100000],[1,1,1,1])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
