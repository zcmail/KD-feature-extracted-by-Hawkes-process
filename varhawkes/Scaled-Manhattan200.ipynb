{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "\n",
    "def trainScaledManhattan(in_vec):\n",
    "    mean = in_vec.mean()\n",
    "    std = in_vec.std()\n",
    "    return mean,std\n",
    "\n",
    "\n",
    "def classifyScaledManhattan(mean,std, q):\n",
    "\n",
    "    if(len(mean) != len(q)):\n",
    "        print (len(mean))\n",
    "        print(len(q))\n",
    "        print(\"Be sure that both vectors are the same dimension!\")\n",
    "        return\n",
    "    for i in range(len(mean)):\n",
    "        if (std[i] == 0):\n",
    "            std[i] = 1e-10\n",
    "\n",
    "    return sum([abs(mean[i]-q[i])/std[i] for i in range(len(q))])\n",
    "\n",
    "def trainEuclidean(in_vec):\n",
    "    mean = in_vec.mean()\n",
    "    return mean\n",
    "\n",
    "def classifyEuclidean(mean,q):\n",
    "    if(len(mean) != len(q)):\n",
    "        print (len(mean))\n",
    "        print(len(q))\n",
    "        print(\"Be sure that both vectors are the same dimension!\")\n",
    "        return\n",
    "    return sum([math.sqrt((mean[i]-q[i])**2) for i in range(len(q))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "#ss = StandardScaler()\n",
    "\n",
    "def train (subject,vectors):\n",
    "    subject_vecs = vectors[vectors['subject']==subject].drop(['subject'],axis=1)[0:200]  #前200个样本训练，后200个样本测试\n",
    "    mean,std = trainScaledManhattan(subject_vecs)\n",
    "    \n",
    "    scores = []   \n",
    "    for i in range(len(subject_vecs)):\n",
    "        score = classifyScaledManhattan(mean,std,subject_vecs.iloc[i])\n",
    "        #print(possitive_score)\n",
    "        scores.append(score)\n",
    "        \n",
    "    threshold = search_threshold(scores,0.05)\n",
    "    #subject_vecs = ss.fit_transform(subject_vecs)    \n",
    "    \n",
    "    return mean,std,threshold\n",
    "\n",
    "def test(subject,vectors):\n",
    "    mean,std,threshold = train(subject,vectors)    #调用训练\n",
    "    #print('mean:',mean)\n",
    "    #print('std:',std)\n",
    "    possitive_samples = vectors[vectors['subject']==subject].drop(['subject'],axis=1)[200:400]  #正样本\n",
    "    #possitive_samples = ss.fit_transform(possitive_samples)\n",
    "    negative_samples = vectors[vectors['subject']!=subject].drop(['subject'],axis=1)\n",
    "    #negative_samples = ss.fit_transform(negative_samples)\n",
    "    \n",
    "    #print(possitive_samples)\n",
    "    #print(negative_samples)\n",
    "    \n",
    "    possitive_scores = []\n",
    "    negative_scores = []\n",
    "    \n",
    "    for i in range(len(possitive_samples)):\n",
    "        possitive_score = classifyScaledManhattan(mean,std,possitive_samples.iloc[i])\n",
    "        #print(possitive_score)\n",
    "        possitive_scores.append(possitive_score)\n",
    "        \n",
    "    for i in range(len(negative_samples)):\n",
    "        negative_score = classifyScaledManhattan(mean,std,negative_samples.iloc[i])\n",
    "        #print(negative_score)\n",
    "        negative_scores.append(negative_score)\n",
    "    return possitive_scores,negative_scores,threshold\n",
    "\n",
    "def search_threshold(scores,threshold):\n",
    "    scores_asc = sorted(scores)\n",
    "    #print(scores_asc)\n",
    "    threshold_index = int(len(scores)*(1-threshold))\n",
    "    return scores_asc[threshold_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s002 miss_rate1 is: 0.19\n",
      "s002 miss_rate2 is: 0.290625\n",
      "s032 miss_rate1 is: 0.24\n",
      "s032 miss_rate2 is: 0.314375\n",
      "s036 miss_rate1 is: 0.0\n",
      "s036 miss_rate2 is: 0.0\n",
      "s047 miss_rate1 is: 0.085\n",
      "s047 miss_rate2 is: 0.475\n",
      "s052 miss_rate1 is: 0.02\n",
      "s052 miss_rate2 is: 0.0\n"
     ]
    }
   ],
   "source": [
    "file_name = './data/CMU_oral_output.xls'\n",
    "df = pd.read_excel(file_name)\n",
    "vectors = df.drop(['key','sessionIndex','rep'],axis=1)\n",
    "\n",
    "subject_list = ['s002','s032','s036','s047','s052']\n",
    "#subject_list = ['s002']\n",
    "CMU_score_list = []\n",
    "CMU_threshold_list = []\n",
    "for subject in subject_list:\n",
    "    positive_scores,negative_scores,threshold = test(subject,vectors)\n",
    "    negative1 = sum(positive_scores>threshold)\n",
    "    negative2 = sum(negative_scores<threshold)\n",
    "    miss_rate1 = negative1/200\n",
    "    miss_rate2 = negative2/1600\n",
    "    print (subject+' miss_rate1 is:',miss_rate1)\n",
    "    print (subject+' miss_rate2 is:',miss_rate2)\n",
    "\n",
    "    CMU_score_list.append(positive_scores+negative_scores),threshold\n",
    "    CMU_threshold_list.append(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s002 miss_rate1 is: 0.245\n",
      "s002 miss_rate2 is: 0.35375\n",
      "s032 miss_rate1 is: 0.15\n",
      "s032 miss_rate2 is: 0.574375\n",
      "s036 miss_rate1 is: 0.065\n",
      "s036 miss_rate2 is: 0.010625\n",
      "s047 miss_rate1 is: 0.23\n",
      "s047 miss_rate2 is: 0.33125\n",
      "s052 miss_rate1 is: 0.135\n",
      "s052 miss_rate2 is: 0.49125\n"
     ]
    }
   ],
   "source": [
    "file_name = './data/CMU_exp_shrink_output_zero_2subject.xls'\n",
    "#file_name = './data/CMU_exp_shrink_output_rep50_2subject.xls'\n",
    "df = pd.read_excel(file_name)\n",
    "vectors = df.drop(['key','session'],axis=1)\n",
    "\n",
    "subject_list = ['s002','s032','s036','s047','s052']\n",
    "Hawkes_SM_score_list = []\n",
    "Hawkes_SM_threshold_list = []\n",
    "\n",
    "for subject in subject_list:\n",
    "    positive_scores,negative_scores,threshold = test(subject,vectors)\n",
    "    negative1 = sum(positive_scores>threshold)\n",
    "    negative2 = sum(negative_scores<threshold)\n",
    "    miss_rate1 = negative1/200\n",
    "    miss_rate2 = negative2/1600\n",
    "    miss_rate = (negative1+negative2)/1800\n",
    "    \n",
    "    \n",
    "    print (subject+' miss_rate1 is:',miss_rate1)\n",
    "    print (subject+' miss_rate2 is:',miss_rate2)\n",
    "    Hawkes_SM_score_list.append(positive_scores+negative_scores)\n",
    "    Hawkes_SM_threshold_list.append(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Hawkes_SM_score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "s002 miss_rate1 is: 0.26\n",
    "s002 miss_rate2 is: 0.3175\n",
    "s002 miss_rate is: 0.3111111111111111\n",
    "s032 miss_rate1 is: 0.15\n",
    "s032 miss_rate2 is: 0.48875\n",
    "s032 miss_rate is: 0.45111111111111113\n",
    "s036 miss_rate1 is: 0.055\n",
    "s036 miss_rate2 is: 0.01125\n",
    "s036 miss_rate is: 0.01611111111111111\n",
    "s047 miss_rate1 is: 0.225\n",
    "s047 miss_rate2 is: 0.21375\n",
    "s047 miss_rate is: 0.215\n",
    "s052 miss_rate1 is: 0.175\n",
    "s052 miss_rate2 is: 0.389375\n",
    "s052 miss_rate is: 0.3655555555555556"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s002 miss_rate1 is: 0.245\n",
    "s002 miss_rate2 is: 0.35375\n",
    "s002 miss_rate is: 0.3416666666666667\n",
    "s032 miss_rate1 is: 0.15\n",
    "s032 miss_rate2 is: 0.574375\n",
    "s032 miss_rate is: 0.5272222222222223\n",
    "s036 miss_rate1 is: 0.065\n",
    "s036 miss_rate2 is: 0.010625\n",
    "s036 miss_rate is: 0.016666666666666666\n",
    "s047 miss_rate1 is: 0.23\n",
    "s047 miss_rate2 is: 0.33125\n",
    "s047 miss_rate is: 0.32\n",
    "s052 miss_rate1 is: 0.135\n",
    "s052 miss_rate2 is: 0.49125\n",
    "s052 miss_rate is: 0.45166666666666666"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "matrix：这就是用户之间的评分或观点等你衡量的东西或你的业务商品的原始矩阵。\n",
    "row_columns：如果你衡量的是列之间的距离，则设为 1；如果你衡量的是行之间的距离，则设为 0；\n",
    "size：所得矩阵的所需大小。也就是说，当寻找用户或商品相似度时，这就是用户或商品的数量。\n",
    "所以如果有 500 个不同用户，则距离矩阵的大小就为 500×500。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def adjusted_cos_distance_matrix(size, matrix, row_column):\n",
    "    distances = np.zeros((size,size))\n",
    "    if row_column == 0:\n",
    "        M_u = matrix.mean(axis=1)\n",
    "        #print('M_u is:',M_u)\n",
    "        m_sub = matrix.as_matrix() - M_u[:,None]\n",
    "        #print('m_sub is:',m_sub)\n",
    "    if row_column == 1:\n",
    "        M_u = matrix.df.as_matrix().T.mean(axis=1)\n",
    "        m_sub = matrix.T - M_u[:,None]\n",
    "    for first in range(0,size):\n",
    "        for sec in range(0,size):\n",
    "            distance = spatial.distance.cosine(m_sub[first],m_sub[sec])\n",
    "            distances[first,sec] = distance\n",
    "    return distances\n",
    "\n",
    "\n",
    "def adjusted_cos_distance(vector1,vector2):\n",
    "    M_u1 = vector1.mean()\n",
    "    M_u2 = vector2.mean()\n",
    "    m_sub1 = vector1 - M_u1\n",
    "    m_sub2 = vector2 - M_u2\n",
    "    distance = spatial.distance.cosine(m_sub1,m_sub2)\n",
    "    return distance\n",
    "\n",
    "def cos_distance_matrix(size, matrix, row_column):\n",
    "    distances = np.zeros((size,size))\n",
    "    if row_column == 0:\n",
    "        m_sub = matrix.as_matrix() \n",
    "        #print('m_sub is:',m_sub)\n",
    "    if row_column == 1:\n",
    "        M_u = matrix.df.as_matrix().T.mean(axis=1)\n",
    "        m_sub = matrix.T\n",
    "    for first in range(0,size):\n",
    "        for sec in range(0,size):\n",
    "            distance = spatial.distance.cosine(m_sub[first],m_sub[sec])\n",
    "            distances[first,sec] = distance\n",
    "    return distances\n",
    "\n",
    "def cos_distance(vector1,vector2):\n",
    "    m_sub1 = vector1\n",
    "    m_sub2 = vector2\n",
    "    distance = spatial.distance.cosine(m_sub1,m_sub2)\n",
    "    return distance\n",
    "\n",
    "\n",
    "#中心点对应的index,0.05false alarm的distance阀值\n",
    "def center (subject,vectors):    #根据前200个样本计算中心点\n",
    "    subject_vecs = vectors[vectors['subject']==subject].drop(['subject'],axis=1)[0:200]\n",
    "    distances = adjusted_cos_distance_matrix(200,subject_vecs,0)\n",
    "    #print(distances)\n",
    "    distances_sum = pd.DataFrame(distances).sum().tolist()\n",
    "    #print(distances_sum)\n",
    "    center_index  = distances_sum.index(min(distances_sum))\n",
    "    return subject_vecs.iloc[center_index]\n",
    "\n",
    "def cosine_threshold (center_vec,vectors):\n",
    "    subject_vecs = vectors[vectors['subject']==subject].drop(['subject'],axis=1)[0:200]\n",
    "    possitive_scores = []\n",
    "    for i in range(len(subject_vecs)):\n",
    "        distance = adjusted_cos_distance(center_vec,subject_vecs.iloc[i])\n",
    "        possitive_scores.append(distance)\n",
    "    #print(sorted(possitive_scores))\n",
    "    threshold = search_threshold(possitive_scores,0.05)\n",
    "    return threshold\n",
    "    \n",
    "\n",
    "def test_possitive(subject,vectors,center_vec,distance_threshold): \n",
    "    positive_vecs = vectors[vectors['subject']==subject].drop(['subject'],axis=1)[200:400]\n",
    "    possitive_scores = []\n",
    "    for i in range(len(positive_vecs)):\n",
    "        distance = adjusted_cos_distance(center_vec,positive_vecs.iloc[i])\n",
    "        possitive_scores.append(distance)\n",
    "    #print(possitive_scores)\n",
    "    negative1 = sum(possitive_scores>distance_threshold)\n",
    "    #print(negative1)\n",
    "    return negative1\n",
    "\n",
    "def test_passitive(subject,vectors,center_vec,distance_threshold):\n",
    "    negative_vecs = vectors[vectors['subject']!=subject].drop(['subject'],axis=1)    \n",
    "    negative_scores = []\n",
    "    for i in range(len(negative_vecs)):\n",
    "        distance = adjusted_cos_distance(center_vec,negative_vecs.iloc[i])\n",
    "        negative_scores.append(distance)\n",
    "    #print(sorted(negative_scores))\n",
    "    negative2 = sum(negative_scores<distance_threshold)\n",
    "    #print(negative2)\n",
    "    return negative2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jw\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7214322914277548\n",
      "s002 miss_rate1 is: 0.05\n",
      "s002 miss_rate2 is: 0.960625\n",
      "s002 miss_rate is: 0.8594444444444445\n",
      "0.8878111969455096\n",
      "s032 miss_rate1 is: 0.075\n",
      "s032 miss_rate2 is: 0.506875\n",
      "s032 miss_rate is: 0.4588888888888889\n",
      "0.008838064280693447\n",
      "s036 miss_rate1 is: 0.215\n",
      "s036 miss_rate2 is: 0.004375\n",
      "s036 miss_rate is: 0.027777777777777776\n",
      "0.9484064703423458\n",
      "s047 miss_rate1 is: 0.015\n",
      "s047 miss_rate2 is: 0.525\n",
      "s047 miss_rate is: 0.4683333333333333\n",
      "1.0338211103178405\n",
      "s052 miss_rate1 is: 0.105\n",
      "s052 miss_rate2 is: 0.433125\n",
      "s052 miss_rate is: 0.39666666666666667\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_name = './data/CMU_exp_shrink_output_zero_4subject.xls'\n",
    "df = pd.read_excel(file_name)\n",
    "vectors = df.drop(['key','session'],axis=1)\n",
    "\n",
    "subject_list = ['s002','s032','s036','s047','s052']\n",
    "#subject_list = ['s002']\n",
    "for subject in subject_list:\n",
    "    center_vec = center(subject,vectors)\n",
    "    distance_threshold =  cosine_threshold(center_vec,vectors)\n",
    "    print(distance_threshold)\n",
    "    negative1 = test_possitive(subject,vectors,center_vec,distance_threshold)\n",
    "    negative2 = test_passitive(subject,vectors,center_vec,distance_threshold)\n",
    "\n",
    "    miss_rate1 = negative1/200\n",
    "    miss_rate2 = negative2/1600\n",
    "    miss_rate = (negative1+negative2)/1800\n",
    "    \n",
    "    print (subject+' miss_rate1 is:',miss_rate1)\n",
    "    print (subject+' miss_rate2 is:',miss_rate2)\n",
    "    print (subject+' miss_rate is:',miss_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.5616951734955056\n",
    "s002 miss_rate1 is: 0.08\n",
    "s002 miss_rate2 is: 0.935625\n",
    "s002 miss_rate is: 0.8405555555555555\n",
    "0.7226487117327514\n",
    "s032 miss_rate1 is: 0.075\n",
    "s032 miss_rate2 is: 0.5\n",
    "s032 miss_rate is: 0.4527777777777778\n",
    "0.009924702209332947\n",
    "s036 miss_rate1 is: 0.18\n",
    "s036 miss_rate2 is: 0.004375\n",
    "s036 miss_rate is: 0.02388888888888889\n",
    "0.8455684268458977\n",
    "s047 miss_rate1 is: 0.01\n",
    "s047 miss_rate2 is: 0.55\n",
    "s047 miss_rate is: 0.49\n",
    "0.8829980152346092\n",
    "s052 miss_rate1 is: 0.105\n",
    "s052 miss_rate2 is: 0.4375\n",
    "s052 miss_rate is: 0.40055555555555555"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#中心点对应的index,0.05false alarm的distance阀值\n",
    "def center2 (subject,vectors):    #根据前200个样本计算中心点\n",
    "    subject_vecs = vectors[vectors['subject']==subject].drop(['subject'],axis=1)[0:200]\n",
    "    distances = cos_distance_matrix(200,subject_vecs,0)\n",
    "    #print(distances)\n",
    "    distances_sum = pd.DataFrame(distances).sum().tolist()\n",
    "    #print(distances_sum)\n",
    "    center_index  = distances_sum.index(min(distances_sum))\n",
    "    return subject_vecs.iloc[center_index]\n",
    "\n",
    "def cosine_threshold2 (center_vec,vectors):\n",
    "    subject_vecs = vectors[vectors['subject']==subject].drop(['subject'],axis=1)[0:200]\n",
    "    possitive_scores = []\n",
    "    for i in range(len(subject_vecs)):\n",
    "        distance = cos_distance(center_vec,subject_vecs.iloc[i])\n",
    "        possitive_scores.append(distance)\n",
    "    #print(sorted(possitive_scores))\n",
    "    threshold = search_threshold(possitive_scores,0.05)\n",
    "    return threshold\n",
    "    \n",
    "\n",
    "def test_possitive2(subject,vectors,center_vec,distance_threshold): \n",
    "    positive_vecs = vectors[vectors['subject']==subject].drop(['subject'],axis=1)[200:400]\n",
    "    possitive_scores = []\n",
    "    for i in range(len(positive_vecs)):\n",
    "        distance = cos_distance(center_vec,positive_vecs.iloc[i])\n",
    "        possitive_scores.append(distance)\n",
    "    #print(possitive_scores)\n",
    "    negative1 = sum(possitive_scores>distance_threshold)\n",
    "    #print(negative1)\n",
    "    return negative1\n",
    "\n",
    "def test_passitive2(subject,vectors,center_vec,distance_threshold):\n",
    "    negative_vecs = vectors[vectors['subject']!=subject].drop(['subject'],axis=1)    \n",
    "    negative_scores = []\n",
    "    for i in range(len(negative_vecs)):\n",
    "        distance = cos_distance(center_vec,negative_vecs.iloc[i])\n",
    "        negative_scores.append(distance)\n",
    "    #print(sorted(negative_scores))\n",
    "    negative2 = sum(negative_scores<distance_threshold)\n",
    "    #print(negative2)\n",
    "    return negative2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jw\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34783629480271405\n",
      "s002 miss_rate1 is: 0.055\n",
      "s002 miss_rate2 is: 0.6325\n",
      "s002 miss_rate is: 0.5683333333333334\n",
      "0.5015331083634932\n",
      "s032 miss_rate1 is: 0.05\n",
      "s032 miss_rate2 is: 0.5075\n",
      "s032 miss_rate is: 0.45666666666666667\n",
      "0.008460835278300438\n",
      "s036 miss_rate1 is: 0.28\n",
      "s036 miss_rate2 is: 0.004375\n",
      "s036 miss_rate is: 0.035\n",
      "0.29038482759039963\n",
      "s047 miss_rate1 is: 0.045\n",
      "s047 miss_rate2 is: 0.3475\n",
      "s047 miss_rate is: 0.3138888888888889\n",
      "0.5618527536757371\n",
      "s052 miss_rate1 is: 0.105\n",
      "s052 miss_rate2 is: 0.430625\n",
      "s052 miss_rate is: 0.39444444444444443\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_name = './data/CMU_exp_shrink_output_zero_4subject.xls'\n",
    "df = pd.read_excel(file_name)\n",
    "vectors = df.drop(['key','session'],axis=1)\n",
    "\n",
    "subject_list = ['s002','s032','s036','s047','s052']\n",
    "#subject_list = ['s002']\n",
    "for subject in subject_list:\n",
    "    center_vec = center2(subject,vectors)\n",
    "    distance_threshold =  cosine_threshold2(center_vec,vectors)\n",
    "    print(distance_threshold)\n",
    "    negative1 = test_possitive2(subject,vectors,center_vec,distance_threshold)\n",
    "    negative2 = test_passitive2(subject,vectors,center_vec,distance_threshold)\n",
    "\n",
    "    miss_rate1 = negative1/200\n",
    "    miss_rate2 = negative2/1600\n",
    "    miss_rate = (negative1+negative2)/1800\n",
    "    \n",
    "    print (subject+' miss_rate1 is:',miss_rate1)\n",
    "    print (subject+' miss_rate2 is:',miss_rate2)\n",
    "    print (subject+' miss_rate is:',miss_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s002 miss_rate is: 0.385\n",
    "s032 miss_rate is: 0.63375\n",
    "s036 miss_rate is: 0.000625\n",
    "s047 miss_rate is: 0.239375\n",
    "s052 miss_rate is: 0.493125"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s002 miss_rate is: 0.290625\n",
    "s032 miss_rate is: 0.314375\n",
    "s036 miss_rate is: 0.0\n",
    "s047 miss_rate is: 0.475\n",
    "s052 miss_rate is: 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#试试欧氏距离\n",
    "\n",
    "def train_Euclidean (subject,vectors):\n",
    "    subject_vecs = vectors[vectors['subject']==subject].drop(['subject'],axis=1)[0:200]  #前200个样本训练，后200个样本测试\n",
    "    mean = trainEuclidean(subject_vecs)\n",
    "    \n",
    "    scores = []   \n",
    "    for i in range(len(subject_vecs)):\n",
    "        score = classifyEuclidean(mean,subject_vecs.iloc[i])\n",
    "        #print(score)\n",
    "        scores.append(score)\n",
    "        \n",
    "    threshold = search_threshold(scores,0.05)\n",
    "    #subject_vecs = ss.fit_transform(subject_vecs)    \n",
    "    \n",
    "    return mean,threshold\n",
    "\n",
    "def test_Euclidean(subject,vectors):\n",
    "    mean,threshold = train_Euclidean(subject,vectors)    #调用训练\n",
    "    #print('mean:',mean)\n",
    "    #print('std:',std)\n",
    "    possitive_samples = vectors[vectors['subject']==subject].drop(['subject'],axis=1)[200:400]  #正样本\n",
    "    #possitive_samples = ss.fit_transform(possitive_samples)\n",
    "    negative_samples = vectors[vectors['subject']!=subject].drop(['subject'],axis=1)\n",
    "    #negative_samples = ss.fit_transform(negative_samples)\n",
    "    \n",
    "    #print(possitive_samples)\n",
    "    #print(negative_samples)\n",
    "    \n",
    "    possitive_scores = []\n",
    "    negative_scores = []\n",
    "    \n",
    "    for i in range(len(possitive_samples)):\n",
    "        possitive_score = classifyEuclidean(mean,possitive_samples.iloc[i])\n",
    "        #print(possitive_score)\n",
    "        possitive_scores.append(possitive_score)\n",
    "        \n",
    "    for i in range(len(negative_samples)):\n",
    "        negative_score = classifyEuclidean(mean,negative_samples.iloc[i])\n",
    "        #print(negative_score)\n",
    "        negative_scores.append(negative_score)\n",
    "    return possitive_scores,negative_scores,threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s002 miss_rate1 is: 0.125\n",
      "s002 miss_rate2 is: 0.435625\n",
      "s032 miss_rate1 is: 0.08\n",
      "s032 miss_rate2 is: 0.54875\n",
      "s036 miss_rate1 is: 0.165\n",
      "s036 miss_rate2 is: 0.0\n",
      "s047 miss_rate1 is: 0.115\n",
      "s047 miss_rate2 is: 0.2375\n",
      "s052 miss_rate1 is: 0.125\n",
      "s052 miss_rate2 is: 0.37125\n"
     ]
    }
   ],
   "source": [
    "file_name = './data/CMU_exp_shrink_output_zero_2subject.xls'\n",
    "#file_name = './data/CMU_exp_shrink_output_rep50_2subject.xls'\n",
    "df = pd.read_excel(file_name)\n",
    "vectors = df.drop(['key','session'],axis=1)\n",
    "\n",
    "Hawkes_E_score_list = []\n",
    "Hawkes_E_threshold_list = []\n",
    "\n",
    "for subject in subject_list:\n",
    "    positive_scores,negative_scores,threshold = test_Euclidean(subject,vectors)\n",
    "    negative1 = sum(i > threshold for i in positive_scores)\n",
    "    negative2 = sum(i < threshold for i in negative_scores)\n",
    "    \n",
    "    miss_rate1 = negative1/200\n",
    "    miss_rate2 = negative2/1600\n",
    "    miss_rate = (negative1+negative2)/1800\n",
    "    \n",
    "    \n",
    "    print (subject+' miss_rate1 is:',miss_rate1)\n",
    "    print (subject+' miss_rate2 is:',miss_rate2)\n",
    "    Hawkes_E_score_list.append(positive_scores+negative_scores) \n",
    "    Hawkes_E_threshold_list.append(threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s002 miss_rate is: 0.5375\n",
    "s032 miss_rate is: 0.7125\n",
    "s036 miss_rate is: 0.000625\n",
    "s047 miss_rate is: 0.27375\n",
    "s052 miss_rate is: 0.6125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Hawkes_E_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "subject_list = ['s002','s032','s036','s047','s052']\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "path = './result/pohmm_result/200_train_400_test/'\n",
    "\n",
    "POHMM_score_list = []\n",
    "POHMM_threshold_list = []\n",
    "\n",
    "#数据准备\n",
    "def pre_data(subject):\n",
    "    fileName = path +subject+ '_200vs400train_verification_results_out.csv'\n",
    "    df = pd.read_csv(fileName)\n",
    "    df_train = df[0:200]\n",
    "    #正测试样本\n",
    "    df_positive = df[200:400]\n",
    "    #负测试样本\n",
    "    df_negative = df[400:2000]\n",
    "\n",
    "    train_scores = df_train['score'].tolist()\n",
    "    #y_positive = [1]*200\n",
    "    #y_negative =  [0]*1600\n",
    "    y_positive_scores = df_positive['score'].tolist() \n",
    "    y_negative_scores = df_negative['score'].tolist()\n",
    "    return train_scores,y_positive_scores+y_negative_scores\n",
    "\n",
    "\n",
    "subject_list = ['s002','s032','s036','s047','s052']\n",
    "#subject_list = ['s002']\n",
    "for subject in subject_list:\n",
    "    train_scores,scores = pre_data(subject)\n",
    "    score_threshold = search_threshold(train_scores,0.05)\n",
    "    POHMM_score_list.append(scores)\n",
    "    POHMM_threshold_list.append(score_threshold)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(POHMM_threshold_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport matplotlib.pyplot as plt\\nfrom sklearn.metrics import roc_curve, auc  ###计算roc和auc\\n\\n\\nfor i,user in enumerate(subject_list):\\n    POHMM = POHMM_score_list[i]\\n    POHMM_threshold = POHMM_threshold_list[i]\\n    POHMM_pre = [i < POHMM_threshold  for i in POHMM]\\n    \\n    CMU_raw = CMU_score_list[i]\\n    CMU_threshold = CMU_threshold_list[i]\\n    CMU_pre = [i < CMU_threshold  for i in CMU_raw]\\n    \\n    Hawkes_SM = Hawkes_SM_score_list[i]\\n    Hawkes_SM_threshold = Hawkes_SM_threshold_list[i]\\n    Hawkes_SM_pre = [i < Hawkes_SM_threshold  for i in Hawkes_SM]\\n    \\n    Hawkes_E = Hawkes_E_score_list[i]\\n    Hawkes_E_threshold = Hawkes_E_threshold_list[i]\\n    Hawkes_E_threshold = [i < Hawkes_E_threshold  for i in Hawkes_E]\\n    \\n       \\n    y = [True]*200+[False]*1600\\n    \\n    \\n    \\n    fpr_1, tpr_1, threshold_1 = roc_curve(y,CMU_pre)  ###计算真正率和假正率\\n    roc_auc_1 = auc(fpr_1, tpr_1)  ###计算auc的值\\n    \\n    fpr_2, tpr_2, threshold_2 = roc_curve(y,POHMM_pre)  ###计算真正率和假正率\\n    roc_auc_2 = auc(fpr_2, tpr_2)  ###计算auc的值    \\n    \\n    fpr_3, tpr_3, threshold_3 = roc_curve(y,Hawkes_SM_pre)  ###计算真正率和假正率\\n    roc_auc_3 = auc(fpr_3, tpr_3)  ###计算auc的值\\n    \\n    fpr_4, tpr_4, threshold_4 = roc_curve(y,Hawkes_E_pre)  ###计算真正率和假正率\\n    roc_auc_4 = auc(fpr_4, tpr_4)  ###计算auc的值\\n    \\n    plt.figure(figsize=(8, 8))\\n    plt.plot(fpr_1, tpr_1, color=\\'darkorange\\', ###假正率为横坐标，真正率为纵坐标做曲线\\n             lw=2, label=\\'CMU ora data - Scaled Manhattan (area = %0.3f)\\' % roc_auc_1, linestyle=\\'-\\')\\n    plt.plot(fpr_2, tpr_2, color=\\'red\\',\\n             lw=2, label=\\'POHMM (area = %0.3f)\\' % roc_auc_2, linestyle=\\'-\\')\\n    plt.plot(fpr_3, tpr_3, color=\\'blue\\',\\n             lw=2, label=\\'Hawkes feature - Scaled Manhattan (area = %0.3f)\\' % roc_auc_3, linestyle=\\'--\\')\\n    plt.plot(fpr_4, tpr_4, color=\\'#800080\\',\\n             lw=2, label=\\'Hawkes feature - Euclidean  (area = %0.3f)\\' % roc_auc_4, linestyle=\\'--\\')\\n\\n    plt.plot([0, 1], [0, 1], color=\\'navy\\', lw=2, linestyle=\\'--\\')\\n    plt.xlim([-0.02, 1.05])#横竖增加一点长度 以便更好观察图像\\n    plt.ylim([-0.02, 1.05])\\n    plt.xlabel(\\'False Positive Rate\\')\\n    plt.ylabel(\\'True Positive Rate\\')\\n    plt.title(\\'different feature comparison of \\'+user)\\n    plt.legend(loc=\"lower right\")\\n    #save_file = object_user+\\'_200vs400samples.png\\'\\n    #plt.savefig(save_file,dpi=600)#保存图片，dpi设置分辨率\\n    plt.show()\\n'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc  ###计算roc和auc\n",
    "\n",
    "\n",
    "for i,user in enumerate(subject_list):\n",
    "    POHMM = POHMM_score_list[i]\n",
    "    POHMM_threshold = POHMM_threshold_list[i]\n",
    "    POHMM_pre = [i < POHMM_threshold  for i in POHMM]\n",
    "    \n",
    "    CMU_raw = CMU_score_list[i]\n",
    "    CMU_threshold = CMU_threshold_list[i]\n",
    "    CMU_pre = [i < CMU_threshold  for i in CMU_raw]\n",
    "    \n",
    "    Hawkes_SM = Hawkes_SM_score_list[i]\n",
    "    Hawkes_SM_threshold = Hawkes_SM_threshold_list[i]\n",
    "    Hawkes_SM_pre = [i < Hawkes_SM_threshold  for i in Hawkes_SM]\n",
    "    \n",
    "    Hawkes_E = Hawkes_E_score_list[i]\n",
    "    Hawkes_E_threshold = Hawkes_E_threshold_list[i]\n",
    "    Hawkes_E_threshold = [i < Hawkes_E_threshold  for i in Hawkes_E]\n",
    "    \n",
    "       \n",
    "    y = [True]*200+[False]*1600\n",
    "    \n",
    "    \n",
    "    \n",
    "    fpr_1, tpr_1, threshold_1 = roc_curve(y,CMU_pre)  ###计算真正率和假正率\n",
    "    roc_auc_1 = auc(fpr_1, tpr_1)  ###计算auc的值\n",
    "    \n",
    "    fpr_2, tpr_2, threshold_2 = roc_curve(y,POHMM_pre)  ###计算真正率和假正率\n",
    "    roc_auc_2 = auc(fpr_2, tpr_2)  ###计算auc的值    \n",
    "    \n",
    "    fpr_3, tpr_3, threshold_3 = roc_curve(y,Hawkes_SM_pre)  ###计算真正率和假正率\n",
    "    roc_auc_3 = auc(fpr_3, tpr_3)  ###计算auc的值\n",
    "    \n",
    "    fpr_4, tpr_4, threshold_4 = roc_curve(y,Hawkes_E_pre)  ###计算真正率和假正率\n",
    "    roc_auc_4 = auc(fpr_4, tpr_4)  ###计算auc的值\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.plot(fpr_1, tpr_1, color='darkorange', ###假正率为横坐标，真正率为纵坐标做曲线\n",
    "             lw=2, label='CMU ora data - Scaled Manhattan (area = %0.3f)' % roc_auc_1, linestyle='-')\n",
    "    plt.plot(fpr_2, tpr_2, color='red',\n",
    "             lw=2, label='POHMM (area = %0.3f)' % roc_auc_2, linestyle='-')\n",
    "    plt.plot(fpr_3, tpr_3, color='blue',\n",
    "             lw=2, label='Hawkes feature - Scaled Manhattan (area = %0.3f)' % roc_auc_3, linestyle='--')\n",
    "    plt.plot(fpr_4, tpr_4, color='#800080',\n",
    "             lw=2, label='Hawkes feature - Euclidean  (area = %0.3f)' % roc_auc_4, linestyle='--')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([-0.02, 1.05])#横竖增加一点长度 以便更好观察图像\n",
    "    plt.ylim([-0.02, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('different feature comparison of '+user)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    #save_file = object_user+'_200vs400samples.png'\n",
    "    #plt.savefig(save_file,dpi=600)#保存图片，dpi设置分辨率\n",
    "    plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
